{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPK9Wppzdl+5u1aLmbwtcB8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qrpf53FWH3tP"},"outputs":[],"source":["#@title FFTConv2D Tensorflow Keras\n","\n","import functools\n","\n","from tensorflow.python.eager import context\n","from tensorflow.python.framework import tensor_shape\n","from tensorflow.python.keras import activations\n","from tensorflow.python.keras import backend\n","from tensorflow.python.keras import constraints\n","from tensorflow.python.keras import initializers\n","from tensorflow.python.keras import regularizers\n","from tensorflow.keras.layers import Layer\n","from tensorflow.keras.layers import InputSpec\n","# imports for backwards namespace compatibility\n","# pylint: disable=unused-import\n","from tensorflow.python.keras.layers.pooling import AveragePooling1D\n","from tensorflow.python.keras.layers.pooling import AveragePooling2D\n","from tensorflow.python.keras.layers.pooling import AveragePooling3D\n","from tensorflow.python.keras.layers.pooling import MaxPooling1D\n","from tensorflow.python.keras.layers.pooling import MaxPooling2D\n","from tensorflow.python.keras.layers.pooling import MaxPooling3D\n","# pylint: enable=unused-import\n","from tensorflow.python.keras.utils import conv_utils\n","from tensorflow.python.keras.utils import tf_utils\n","from tensorflow.python.ops import array_ops\n","from tensorflow.python.ops import array_ops_stack\n","from tensorflow.python.ops import nn\n","from tensorflow.python.ops import nn_ops\n","# pylint: disable=g-classes-have-attributes\n","from tensorflow.keras.utils import register_keras_serializable\n","\n","@register_keras_serializable()\n","class FFTConv2D(Layer):\n","\n","  def __init__(self,\n","               filters,\n","               kernel_size,\n","               strides=1,\n","               padding='valid',\n","               data_format=None,\n","               dilation_rate=1,\n","               groups=1,\n","               activation=None,\n","               use_bias=True,\n","               kernel_initializer='glorot_uniform',\n","               bias_initializer='zeros',\n","               kernel_regularizer=None,\n","               bias_regularizer=None,\n","               activity_regularizer=None,\n","               kernel_constraint=None,\n","               bias_constraint=None,\n","               trainable=True,\n","               name=None,\n","               conv_op=None,\n","               **kwargs):\n","    super(FFTConv2D, self).__init__(\n","        trainable=trainable,\n","        name=name,\n","        activity_regularizer=regularizers.get(activity_regularizer),\n","        **kwargs)\n","    rank = 2\n","    self.rank = rank\n","\n","    if isinstance(filters, float):\n","      filters = int(filters)\n","    if filters is not None and filters < 0:\n","      raise ValueError(f'Received a negative value for `filters`.'\n","                       f'Was expecting a positive value, got {filters}.')\n","    self.filters = filters\n","    self.groups = groups or 1\n","    self.kernel_size = conv_utils.normalize_tuple(\n","        kernel_size, rank, 'kernel_size')\n","    self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n","    self.padding = conv_utils.normalize_padding(padding)\n","    self.data_format = conv_utils.normalize_data_format(data_format)\n","    self.dilation_rate = conv_utils.normalize_tuple(\n","        dilation_rate, rank, 'dilation_rate')\n","\n","    self.activation = activations.get(activation)\n","    self.use_bias = use_bias\n","    self.conv_op = conv_op\n","\n","    self.kernel_initializer = initializers.get(kernel_initializer)\n","    self.bias_initializer = initializers.get(bias_initializer)\n","    self.kernel_regularizer = regularizers.get(kernel_regularizer)\n","    self.bias_regularizer = regularizers.get(bias_regularizer)\n","    self.kernel_constraint = constraints.get(kernel_constraint)\n","    self.bias_constraint = constraints.get(bias_constraint)\n","    self.input_spec = InputSpec(min_ndim=self.rank + 2)\n","\n","    self._validate_init()\n","    self._is_causal = self.padding == 'causal'\n","    self._channels_first = self.data_format == 'channels_first'\n","    self._tf_data_format = conv_utils.convert_data_format(\n","        self.data_format, self.rank + 2)\n","\n","  def _validate_init(self):\n","    if self.filters is not None and self.filters % self.groups != 0:\n","      raise ValueError(\n","          'The number of filters must be evenly divisible by the number of '\n","          'groups. Received: groups={}, filters={}'.format(\n","              self.groups, self.filters))\n","\n","    if not all(self.kernel_size):\n","      raise ValueError('The argument `kernel_size` cannot contain 0(s). '\n","                       'Received: %s' % (self.kernel_size,))\n","\n","    if not all(self.strides):\n","      raise ValueError('The argument `strides` cannot contains 0(s). '\n","                       'Received: %s' % (self.strides,))\n","\n","    if (self.padding == 'causal' and not isinstance(self,\n","                                                    (FFTConv1D, SeparableConv1D))):\n","      raise ValueError('Causal padding is only supported for `Conv1D`'\n","                       'and `SeparableConv1D`.')\n","\n","  def build(self, input_shape):\n","    input_shape = tensor_shape.TensorShape(input_shape)\n","    input_channel = self._get_input_channel(input_shape)\n","    if input_channel % self.groups != 0:\n","      raise ValueError(\n","          'The number of input channels must be evenly divisible by the number '\n","          'of groups. Received groups={}, but the input has {} channels '\n","          '(full input shape is {}).'.format(self.groups, input_channel,\n","                                             input_shape))\n","    kernel_shape = self.kernel_size + (input_channel // self.groups,\n","                                       self.filters)\n","\n","    self.kernel = self.add_weight(\n","        name='kernel',\n","        shape=kernel_shape,\n","        initializer=self.kernel_initializer,\n","        regularizer=self.kernel_regularizer,\n","        constraint=self.kernel_constraint,\n","        trainable=True,\n","        dtype=self.dtype)\n","    if self.use_bias:\n","      self.bias = self.add_weight(\n","          name='bias',\n","          shape=(self.filters,),\n","          initializer=self.bias_initializer,\n","          regularizer=self.bias_regularizer,\n","          constraint=self.bias_constraint,\n","          trainable=True,\n","          dtype=self.dtype)\n","    else:\n","      self.bias = None\n","    channel_axis = self._get_channel_axis()\n","    self.input_spec = InputSpec(min_ndim=self.rank + 2,\n","                                axes={channel_axis: input_channel})\n","\n","    # Convert Keras formats to TF native formats.\n","    if self.padding == 'causal':\n","      tf_padding = 'VALID'  # Causal padding handled in `call`.\n","    elif isinstance(self.padding, str):\n","      tf_padding = self.padding.upper()\n","    else:\n","      tf_padding = self.padding\n","    tf_dilations = list(self.dilation_rate)\n","    tf_strides = list(self.strides)\n","\n","    tf_op_name = self.__class__.__name__\n","    if tf_op_name == 'FFTConv1D':\n","      tf_op_name = 'fftconv1d'  # Backwards compat.\n","\n","    self._convolution_op = functools.partial(\n","        nn_ops.convolution_v2,\n","        strides=tf_strides,\n","        padding=tf_padding,\n","        dilations=tf_dilations,\n","        data_format=self._tf_data_format,\n","        name=tf_op_name)\n","    self.built = True\n","\n","  def call(self, inputs):\n","    input_shape = inputs.shape\n","\n","    if self._is_causal:  # Apply causal padding to inputs for Conv1D.\n","      inputs = array_ops.pad(inputs, self._compute_causal_padding(inputs))\n","\n","    outputs = self.fft_op(inputs, self.kernel)\n","\n","    if self.use_bias:\n","      output_rank = outputs.shape.rank\n","      if self.rank == 1 and self._channels_first:\n","        # nn.bias_add does not accept a 1D input tensor.\n","        bias = array_ops.reshape(self.bias, (1, self.filters, 1))\n","        outputs += bias\n","      else:\n","        # Handle multiple batch dimensions.\n","        if output_rank is not None and output_rank > 2 + self.rank:\n","\n","          def _apply_fn(o):\n","            return nn.bias_add(o, self.bias, data_format=self._tf_data_format)\n","\n","          outputs = conv_utils.squeeze_batch_dims(\n","              outputs, _apply_fn, inner_rank=self.rank + 1)\n","        else:\n","          outputs = nn.bias_add(\n","              outputs, self.bias, data_format=self._tf_data_format)\n","\n","    if not context.executing_eagerly():\n","      # Infer the static output shape:\n","      out_shape = self.compute_output_shape(input_shape)\n","      outputs.set_shape(out_shape)\n","\n","    if self.activation is not None:\n","      return self.activation(outputs)\n","    return outputs\n","\n","  @tf.function\n","  def fft_op(self, batch_images, kernels_outputs, strides=(1, 1), padding='valid', dilation_rate=(1, 1), data_format='channels_last'):\n","    kernels = tf.transpose(kernels_outputs, perm=[3,0,1,2])\n","\n","    def process_image(image):\n","      channels = tf.transpose(image, perm=[2,0,1])\n","\n","      def process_kernel(kernel):\n","        kernel_channels = tf.transpose(kernel, perm=[2,0,1])\n","\n","        def process_channel(args):\n","          channel, kernel_channel = args\n","\n","          channel = tf.cast(channel, dtype=tf.float32)\n","          kernel_channel = tf.cast(kernel_channel, dtype=tf.float32)\n","\n","          if padding == 'same':\n","              pad_height = max((kernel_channel.shape[0] - 1) // 2, 0)\n","              pad_width = max((kernel_channel.shape[1] - 1) // 2, 0)\n","              channel = tf.pad(channel, paddings=[[pad_height, pad_height], [pad_width, pad_width]])\n","          if channel.shape[0] is not None and channel.shape[1] is not None:\n","            if channel.shape[0] > kernel_channel.shape[0] or channel.shape[1] > kernel_channel.shape[1]:\n","              pad_height_kernel = max(channel.shape[0] - kernel_channel.shape[0], 0)\n","              pad_width_kernel = max(channel.shape[1] - kernel_channel.shape[1], 0)\n","              kernel_channel = tf.pad(kernel_channel, paddings=[[0, pad_height_kernel], [0, pad_width_kernel]])\n","            elif channel.shape[0] < kernel_channel.shape[0] or channel.shape[1] < kernel_channel.shape[1]:\n","              kernel_channel = kernel_channel[:channel.shape[0], :channel.shape[1]]\n","\n","          signal_fft = tf.signal.rfft2d(channel)\n","          kernel_fft = tf.signal.rfft2d(kernel_channel)\n","\n","          result_fft = signal_fft * kernel_fft\n","\n","          return tf.signal.irfft2d(result_fft)\n","\n","        output = tf.concat(tf.vectorized_map(process_channel, (channels, kernel_channels)), axis=-1)\n","        output = tf.transpose(output, perm=[1,2,0])\n","        return tf.reduce_sum(output, axis=-1)\n","\n","      return tf.concat(tf.vectorized_map(process_kernel, kernels), axis=-1)\n","\n","    result_batch = tf.concat(tf.vectorized_map(process_image, batch_images), axis=-1)\n","    result_batch = tf.transpose(result_batch, perm=[0,2,3,1])\n","\n","    return result_batch\n","\n","  def _spatial_output_shape(self, spatial_input_shape):\n","    return [\n","        conv_utils.conv_output_length(\n","            length,\n","            self.kernel_size[i],\n","            padding=self.padding,\n","            stride=self.strides[i],\n","            dilation=self.dilation_rate[i])\n","        for i, length in enumerate(spatial_input_shape)\n","    ]\n","\n","  def compute_output_shape(self, input_shape):\n","    input_shape = tensor_shape.TensorShape(input_shape).as_list()\n","    batch_rank = len(input_shape) - self.rank - 1\n","    if self.data_format == 'channels_last':\n","      return tensor_shape.TensorShape(\n","          input_shape[:batch_rank]\n","          + self._spatial_output_shape(input_shape[batch_rank:-1])\n","          + [self.filters])\n","    else:\n","      return tensor_shape.TensorShape(\n","          input_shape[:batch_rank] + [self.filters] +\n","          self._spatial_output_shape(input_shape[batch_rank + 1:]))\n","\n","  def _recreate_conv_op(self, inputs):  # pylint: disable=unused-argument\n","    return False\n","\n","  def get_config(self):\n","    config = {\n","        'filters':\n","            self.filters,\n","        'kernel_size':\n","            self.kernel_size,\n","        'strides':\n","            self.strides,\n","        'padding':\n","            self.padding,\n","        'data_format':\n","            self.data_format,\n","        'dilation_rate':\n","            self.dilation_rate,\n","        'groups':\n","            self.groups,\n","        'activation':\n","            activations.serialize(self.activation),\n","        'use_bias':\n","            self.use_bias,\n","        'kernel_initializer':\n","            initializers.serialize(self.kernel_initializer),\n","        'bias_initializer':\n","            initializers.serialize(self.bias_initializer),\n","        'kernel_regularizer':\n","            regularizers.serialize(self.kernel_regularizer),\n","        'bias_regularizer':\n","            regularizers.serialize(self.bias_regularizer),\n","        'activity_regularizer':\n","            regularizers.serialize(self.activity_regularizer),\n","        'kernel_constraint':\n","            constraints.serialize(self.kernel_constraint),\n","        'bias_constraint':\n","            constraints.serialize(self.bias_constraint),\n","        'trainable':\n","            self.trainable\n","    }\n","    base_config = super(FFTConv2D, self).get_config()\n","    full_config = dict(list(base_config.items()) + list(config.items()))\n","    return full_config\n","\n","  def _compute_causal_padding(self, inputs):\n","    \"\"\"Calculates padding for 'causal' option for 1-d conv layers.\"\"\"\n","    left_pad = self.dilation_rate[0] * (self.kernel_size[0] - 1)\n","    if getattr(inputs.shape, 'ndims', None) is None:\n","      batch_rank = 1\n","    else:\n","      batch_rank = len(inputs.shape) - 2\n","    if self.data_format == 'channels_last':\n","      causal_padding = [[0, 0]] * batch_rank + [[left_pad, 0], [0, 0]]\n","    else:\n","      causal_padding = [[0, 0]] * batch_rank + [[0, 0], [left_pad, 0]]\n","    return causal_padding\n","\n","  def _get_channel_axis(self):\n","    if self.data_format == 'channels_first':\n","      return -1 - self.rank\n","    else:\n","      return -1\n","\n","  def _get_input_channel(self, input_shape):\n","    channel_axis = self._get_channel_axis()\n","    if input_shape.dims[channel_axis].value is None:\n","      raise ValueError('The channel dimension of the inputs '\n","                       'should be defined. Found `None`.')\n","    return int(input_shape[channel_axis])\n","\n","  def _get_padding_op(self):\n","    if self.padding == 'causal':\n","      op_padding = 'valid'\n","    else:\n","      op_padding = self.padding\n","    if not isinstance(op_padding, (list, tuple)):\n","      op_padding = op_padding.upper()\n","    return op_padding"]},{"cell_type":"code","source":["#@title VFFT-CNN\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Activation, BatchNormalization, Add, Attention\n","from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, SeparableConv2D  # straturi convolutionale si max-pooling\n","from tensorflow.keras.optimizers import RMSprop, SGD, Adadelta, Adam, Nadam\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers.schedules import ExponentialDecay\n","from tensorflow.keras.initializers import RandomNormal, HeNormal, GlorotUniform, GlorotNormal\n","from tensorflow.keras.regularizers import L2, L1L2\n","\n","kernel_regularizer=L2(1e-4)\n","kernel_initializer=GlorotUniform(seed=None)\n","drop_rate = 0.35  # Best value for CIFAR-100 after tuning in range 0.25 - 0.75!\n","psiz=4\n","stri=2\n","\n","#--------------------------  ------------------------------\n","# Define a convolutional block with FFTConv2D\n","def fft_conv_block(inputs, inputs_x, filters, kernel_size, padding, input_shape):\n","    x = FFTConv2D(filters=filters, kernel_size=(kernel_size, kernel_size), padding=padding, input_shape=input_shape, kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)(inputs_x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = MaxPooling2D(pool_size=(psiz, psiz),strides=(stri,stri),padding=padding)(x)\n","    x = Dropout(drop_rate)(x)\n","\n","    return x, inputs\n","\n","def fft_block(inputs, filters, kernel_size, padding,input_shape):\n","    x = FFTConv2D(filters=filters, kernel_size=(kernel_size, kernel_size), padding=padding, input_shape=input_shape, kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)(inputs)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","\n","    return x\n","\n","def create_v_cnn_fft_model(input_shape, num_classes, flat=1, fil=[20], nl=[1], hid=[], csize=15, padding='same'):\n","    inputs = Input(shape=input_shape)\n","    original_inputs = inputs\n","    x = inputs\n","\n","    # First macro-layer - connected to input\n","    if nl[0] > 0:\n","        x = fft_block(x, fil[0], csize, padding, input_shape)\n","        for _ in range(nl[0]):\n","            x = fft_block(x, fil[0], csize, padding, input_shape)\n","        x, inputs = fft_conv_block(inputs, x, fil[0], csize, padding, input_shape)\n","    else:\n","        x, inputs = fft_conv_block(inputs, x, fil[0], csize, padding, input_shape)\n","\n","    # The remaining macro-layers\n","    for layer in range(1, len(fil)):\n","        for _ in range(nl[layer]):\n","            x = fft_block(x, fil[layer], csize, padding, input_shape)\n","        x, inputs = fft_conv_block(inputs, x, fil[layer], csize, padding, input_shape)\n","\n","    # Exit classifier\n","    if flat == 1:\n","        x = Flatten()(x)\n","    elif flat == 0:\n","        x = GlobalAveragePooling2D()(x)\n","\n","    for units in hid:\n","        x = Dense(units, activation='relu')(x)\n","\n","    outputs = Dense(num_classes, activation='softmax')(x)\n","\n","    model = Model(inputs=original_inputs, outputs=outputs)\n","\n","    initial_learning_rate = 0.0001\n","    lr_schedule = ExponentialDecay(\n","        initial_learning_rate,\n","        decay_steps=10000,\n","        decay_rate=0.96,\n","        staircase=True)\n","\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(clipvalue=1.0, learning_rate=initial_learning_rate),\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","\n","    return model\n"],"metadata":{"id":"ebFIJBfSISpe"},"execution_count":null,"outputs":[]}]}